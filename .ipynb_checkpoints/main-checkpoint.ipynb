{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "from utils import *\n",
    "from model import CSRNet\n",
    "import torchvision.transforms as transforms\n",
    "from DatasetConstructor import DatasetConstructor\n",
    "from metrics import *\n",
    "from PIL import Image\n",
    "MAE = 10240000\n",
    "MSE = 10240000\n",
    "import time\n",
    "SHANGHAITECH = \"A\"\n",
    "RATE = 10000000\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data_load\n",
    "img_dir = \"/home/zzn/part_\" + SHANGHAITECH + \"_final/train_data/images\"\n",
    "gt_dir = \"/home/zzn/part_\" + SHANGHAITECH + \"_final/train_data/gt_map\"\n",
    "\n",
    "img_dir_t = \"/home/zzn/part_\" + SHANGHAITECH + \"_final/test_data/images\"\n",
    "gt_dir_t = \"/home/zzn/part_\" + SHANGHAITECH + \"_final/test_data/gt_map\"\n",
    "\n",
    "dataset = DatasetConstructor(img_dir, gt_dir, 300, 1)\n",
    "test_data_set = DatasetConstructor(img_dir_t, gt_dir_t, 182, 182, False)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=1)\n",
    "eval_loader = torch.utils.data.DataLoader(dataset=test_data_set, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the gpu device\n",
    "assert torch.cuda.is_available()\n",
    "cuda_device = torch.device(\"cuda\")\n",
    "\n",
    "# model construct\n",
    "net = CSRNet().to(cuda_device)\n",
    "# net = torch.load(\"/home/zzn/Downloads/CSRNet_pytorch-master/checkpoints/model_1_rate_b_0318_14:07.pkl\").to(cuda_device)\n",
    "gt_map_process_model = GroundTruthProcess(1, 1, 8).to(cuda_device) # to keep the same resolution with the prediction\n",
    "# set optimizer and estimator\n",
    "criterion = Loss().to(cuda_device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), 1e-5)\n",
    "ae_batch = AEBatch().to(cuda_device)\n",
    "se_batch = SEBatch().to(cuda_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 1, 376, 808]' is invalid for input of size 306180",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4d5546c91841>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0;31m# B\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0meval_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m49\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0meval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_gt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_height\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_width\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0meval_groundtruth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgt_map_process_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 1, 376, 808]' is invalid for input of size 306180"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "for epoch_index in range(10000):\n",
    "#     dataset = dataset.train_model().shuffle()\n",
    "    dataset = dataset.shuffle()\n",
    "    for train_img_index, train_img, train_gt, data_ptc in train_loader:\n",
    "        # eval per 100 batch\n",
    "        if step % 1000 == 0:\n",
    "            net.eval()\n",
    "            test_data_set = test_data_set.shuffle()\n",
    "            loss_ = []\n",
    "            MAE_ = []\n",
    "            MSE_ = []\n",
    "            difference_rates = []\n",
    "            \n",
    "            rand_number = random.randint(0, 181)\n",
    "            counter = 0\n",
    "            \n",
    "            for eval_img_index, eval_img, eval_gt, eval_data_ptc in eval_loader:\n",
    "                \n",
    "                image_shape = eval_img.shape\n",
    "                patch_height = int(image_shape[3])\n",
    "                patch_width = int(image_shape[4])\n",
    "                # B\n",
    "                eval_x = eval_img.view(49, 3, patch_height, patch_width)\n",
    "                eval_y = eval_gt.cuda()\n",
    "                eval_groundtruth = gt_map_process_model(eval_y)\n",
    "                \n",
    "                patch_height = int(patch_height / 8)\n",
    "                \n",
    "                patch_width = int(patch_width / 8)\n",
    "                \n",
    "                prediction_map = torch.zeros(gt_shape).cuda()\n",
    "                \n",
    "                for i in range(7):\n",
    "                    for j in range(7):\n",
    "                        eval_x_sample = eval_x[i * 7 + j:i * 7 + j + 1].cuda()\n",
    "                        eval_prediction = net(eval_x_sample)\n",
    "                        start_h = int(patch_height / 4)\n",
    "                        start_w = int(patch_width / 4)\n",
    "                        valid_h = int(patch_height / 2)\n",
    "                        valid_w = int(patch_width / 2)\n",
    "                        h_pred = 3 * int(patch_height / 4) + 2 * int(patch_height / 4) * (i - 1)\n",
    "                        w_pred = 3 * int(patch_width / 4) + 2 * int(patch_width / 4) * (j - 1) \n",
    "                        if i == 0:\n",
    "                            valid_h = int((3 * patch_height) / 4)\n",
    "                            start_h = 0\n",
    "                            h_pred = 0\n",
    "                        elif i == 6:\n",
    "                            valid_h = int((3 * patch_height) / 4)\n",
    "                            \n",
    "                        if j == 0:\n",
    "                            valid_w = int((3 * patch_width) / 4)\n",
    "                            start_w = 0\n",
    "                            w_pred = 0\n",
    "                        elif j == 6:\n",
    "                            valid_w = int((3 * patch_width) / 4)\n",
    "                        \n",
    "                        prediction_map[:, :, h_pred:h_pred + valid_h, w_pred:w_pred + valid_w] += eval_prediction[:, :, start_h:start_h + valid_h, start_w:start_w + valid_w]\n",
    "                # That’s because numpy doesn’t support CUDA, \n",
    "                # so there’s no way to make it use GPU memory without a copy to CPU first. \n",
    "                # Remember that .numpy() doesn’t do any copy, \n",
    "                # but returns an array that uses the same memory as the tensor\n",
    "                eval_loss = criterion(prediction_map, eval_groundtruth).data.cpu().numpy()\n",
    "                batch_ae = ae_batch(prediction_map, eval_groundtruth).data.cpu().numpy()\n",
    "                batch_se = se_batch(prediction_map, eval_groundtruth).data.cpu().numpy()\n",
    "                \n",
    "                validate_pred_map = np.squeeze(prediction_map.permute(0, 2, 3, 1).data.cpu().numpy())\n",
    "                validate_gt_map = np.squeeze(eval_groundtruth.permute(0, 2, 3, 1).data.cpu().numpy())\n",
    "                gt_counts = np.sum(validate_gt_map)\n",
    "                pred_counts = np.sum(validate_pred_map)\n",
    "                # random show 1 sample\n",
    "                if rand_number == counter:\n",
    "                    origin_image = Image.open(\"/home/zzn/part_\" + SHANGHAITECH + \"_final/test_data/images/IMG_\" + str(eval_img_index.numpy()[0]) + \".jpg\")\n",
    "                    show(origin_image, validate_gt_map, validate_pred_map, eval_img_index.numpy()[0])\n",
    "                    sys.stdout.write('The gt counts of the above sample:{}, and the pred counts:{}\\n'.format(gt_counts, pred_counts))                        \n",
    "                \n",
    "                difference_rates.append(np.abs(gt_counts - pred_counts) / gt_counts)\n",
    "                loss_.append(eval_loss)\n",
    "                MAE_.append(batch_ae)\n",
    "                MSE_.append(batch_se)\n",
    "                counter += 1\n",
    "            \n",
    "            # calculate the validate loss, validate MAE and validate RMSE\n",
    "            loss_ = np.reshape(loss_, [-1])\n",
    "            MAE_ = np.reshape(MAE_, [-1])\n",
    "            MSE_ = np.reshape(MSE_, [-1])\n",
    "            \n",
    "            validate_loss = np.mean(loss_)\n",
    "            validate_MAE = np.mean(MAE_)\n",
    "            validate_RMSE = np.sqrt(np.mean(MSE_))\n",
    "            validate_rate = np.mean(difference_rates)\n",
    "            \n",
    "            sys.stdout.write('In step {}, epoch {}, with loss {}, rate = {}, MAE = {}, MSE = {}\\n'.format(step, epoch_index + 1, validate_loss, validate_rate, validate_MAE, validate_RMSE))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            if RATE > validate_rate:\n",
    "                RATE = validate_rate\n",
    "                torch.save(net, \"/home/zzn/Downloads/CSRNet_pytorch-master/checkpoints/model_rate_a.pkl\")\n",
    "            \n",
    "            # save model\n",
    "            if MAE > validate_MAE:\n",
    "                MAE = validate_MAE\n",
    "                torch.save(net, \"/home/zzn/Downloads/CSRNet_pytorch-master/checkpoints/model_mae_a.pkl\")\n",
    "                \n",
    "            # save model\n",
    "            if MSE > validate_RMSE:\n",
    "                MSE = validate_RMSE\n",
    "                torch.save(net, \"/home/zzn/Downloads/CSRNet_pytorch-master/checkpoints/model_mse_a.pkl\")\n",
    "            \n",
    "            torch.save(net, \"/home/zzn/Downloads/CSRNet_pytorch-master/checkpoints/model_in_time_a.pkl\")\n",
    "            \n",
    "            # return train model\n",
    "            \n",
    "            \n",
    "        net.train()\n",
    "#         dataset = dataset.train_model()\n",
    "        optimizer.zero_grad()\n",
    "        # B\n",
    "        x = train_img.cuda()\n",
    "        y = train_gt.cuda()\n",
    "        groundtruth = gt_map_process_model(y)\n",
    "        prediction = net(x)\n",
    "        loss = criterion(prediction, groundtruth)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-250. -250. -250. ... -250. -250. -250.]\n",
      " [-249. -249. -249. ... -249. -249. -249.]\n",
      " [-248. -248. -248. ... -248. -248. -248.]\n",
      " ...\n",
      " [ 247.  247.  247. ...  247.  247.  247.]\n",
      " [ 248.  248.  248. ...  248.  248.  248.]\n",
      " [ 249.  249.  249. ...  249.  249.  249.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "map_rand = np.random.randn(500, 500)\n",
    "for i in range(500):\n",
    "    for j in range(500):\n",
    "        map_rand[i][j] = -250 + i\n",
    "print(map_rand)\n",
    "figure, orgin = plt.subplots(1, 1, figsize=(20, 4))\n",
    "orgin.imshow(map_rand, cmap=plt.cm.jet)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "该层的结构：[64, 3, 3, 3]\n",
      "该层参数和：1728\n",
      "该层的结构：[64]\n",
      "该层参数和：64\n",
      "该层的结构：[64, 64, 3, 3]\n",
      "该层参数和：36864\n",
      "该层的结构：[64]\n",
      "该层参数和：64\n",
      "该层的结构：[128, 64, 3, 3]\n",
      "该层参数和：73728\n",
      "该层的结构：[128]\n",
      "该层参数和：128\n",
      "该层的结构：[128, 128, 3, 3]\n",
      "该层参数和：147456\n",
      "该层的结构：[128]\n",
      "该层参数和：128\n",
      "该层的结构：[256, 128, 3, 3]\n",
      "该层参数和：294912\n",
      "该层的结构：[256]\n",
      "该层参数和：256\n",
      "该层的结构：[256, 256, 3, 3]\n",
      "该层参数和：589824\n",
      "该层的结构：[256]\n",
      "该层参数和：256\n",
      "该层的结构：[256, 256, 3, 3]\n",
      "该层参数和：589824\n",
      "该层的结构：[256]\n",
      "该层参数和：256\n",
      "该层的结构：[512, 256, 3, 3]\n",
      "该层参数和：1179648\n",
      "该层的结构：[512]\n",
      "该层参数和：512\n",
      "该层的结构：[512, 512, 3, 3]\n",
      "该层参数和：2359296\n",
      "该层的结构：[512]\n",
      "该层参数和：512\n",
      "该层的结构：[512, 512, 3, 3]\n",
      "该层参数和：2359296\n",
      "该层的结构：[512]\n",
      "该层参数和：512\n",
      "总参数数量和：7635264\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = list(list(net.children())[0].parameters())\n",
    "k = 0\n",
    "for i in params:\n",
    "    l = 1\n",
    "    print(\"该层的结构：\" + str(list(i.size())))\n",
    "    for j in i.size():\n",
    "        l *= j\n",
    "    \n",
    "    print(\"该层参数和：\" + str(l))\n",
    "    \n",
    "    k = k + l\n",
    "print(\"总参数数量和：\" + str(k))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
